{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a65c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be3b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Always load from the project root\n",
    "#env_path = Path(__file__).resolve().parent.parent / \".env\"\n",
    "#load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# env_path = Path(os.getcwd()).parent / \".env\"\n",
    "\n",
    "# env_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de80b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa2bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4515cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e3bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffaaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the capital of France?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5c2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6adec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfcacd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=embedding_model.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efaa67ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e69d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04257791489362717,\n",
       " -0.047810737043619156,\n",
       " -0.02702580951154232,\n",
       " -0.035097863525152206,\n",
       " 0.05324113741517067,\n",
       " 0.0018493696115911007,\n",
       " 0.004823467694222927,\n",
       " -0.022051338106393814,\n",
       " 0.0009697225177660584,\n",
       " 0.07324519753456116,\n",
       " -0.014812891371548176,\n",
       " 0.003644853364676237,\n",
       " -0.00034491211408749223,\n",
       " 0.028128888458013535,\n",
       " 0.025020018219947815,\n",
       " -0.04156218096613884,\n",
       " 0.005471833515912294,\n",
       " 0.02652869001030922,\n",
       " 0.043672770261764526,\n",
       " -0.014782802201807499,\n",
       " 0.013127882033586502,\n",
       " 0.007567551918327808,\n",
       " -0.03469207510352135,\n",
       " 0.023462051525712013,\n",
       " 0.020962651818990707,\n",
       " -0.05559537559747696,\n",
       " 0.00859882216900587,\n",
       " -0.04824773594737053,\n",
       " -0.012368501164019108,\n",
       " -0.001532181748189032,\n",
       " -0.07255345582962036,\n",
       " 0.04269229248166084,\n",
       " 0.00527808116748929,\n",
       " -0.015593086369335651,\n",
       " 0.02645784802734852,\n",
       " -0.0531519278883934,\n",
       " -0.0004922056687064469,\n",
       " 0.016876710578799248,\n",
       " -0.00814562477171421,\n",
       " 0.04225021228194237,\n",
       " -0.015036126598715782,\n",
       " -0.003916633781045675,\n",
       " -0.04687097668647766,\n",
       " 0.015219401568174362,\n",
       " -0.009408559650182724,\n",
       " -0.01825689896941185,\n",
       " -0.01993844285607338,\n",
       " 0.0748581662774086,\n",
       " 0.019254358485341072,\n",
       " -0.0052777305245399475,\n",
       " 0.012134595774114132,\n",
       " -0.010617725551128387,\n",
       " 0.054592013359069824,\n",
       " 0.020773116499185562,\n",
       " 0.013602628372609615,\n",
       " -0.06971295922994614,\n",
       " 0.008997276425361633,\n",
       " -0.014119189232587814,\n",
       " -0.0046128276735544205,\n",
       " 0.0210944302380085,\n",
       " 0.0329081267118454,\n",
       " -0.030065499246120453,\n",
       " 0.00447330716997385,\n",
       " 0.0407467782497406,\n",
       " 0.01971225067973137,\n",
       " -0.055106159299612045,\n",
       " 0.03556030988693237,\n",
       " 0.013304406777024269,\n",
       " 0.08534496277570724,\n",
       " 0.00158949033357203,\n",
       " -0.004593267105519772,\n",
       " -0.042083490639925,\n",
       " 0.0713706836104393,\n",
       " 0.005657872185111046,\n",
       " 0.030689362436532974,\n",
       " -0.0817095935344696,\n",
       " -0.02232016995549202,\n",
       " 0.06454379111528397,\n",
       " 0.01360271591693163,\n",
       " -0.04246792569756508,\n",
       " -0.00804409384727478,\n",
       " -0.05186443775892258,\n",
       " -0.07956809550523758,\n",
       " -0.02714453637599945,\n",
       " -0.05819103121757507,\n",
       " 0.014083041809499264,\n",
       " -0.05621412768959999,\n",
       " -0.018843192607164383,\n",
       " -0.05411393195390701,\n",
       " 0.04985203966498375,\n",
       " -0.025272108614444733,\n",
       " 0.006586411036550999,\n",
       " 0.07480309158563614,\n",
       " -0.040020957589149475,\n",
       " -0.028987407684326172,\n",
       " 0.06478418409824371,\n",
       " -0.014494857750833035,\n",
       " -0.011784432455897331,\n",
       " 0.07746846228837967,\n",
       " -0.003581888973712921,\n",
       " 0.01965465024113655,\n",
       " -0.021930739283561707,\n",
       " -0.07060352712869644,\n",
       " 0.05417868122458458,\n",
       " 0.03164941444993019,\n",
       " -0.00866173766553402,\n",
       " -0.01214554999023676,\n",
       " 0.058456458151340485,\n",
       " 0.006299072410911322,\n",
       " 0.06679613888263702,\n",
       " -0.0667213425040245,\n",
       " -0.04552998021245003,\n",
       " 0.031006908044219017,\n",
       " 0.06095348298549652,\n",
       " 0.01496248971670866,\n",
       " -0.05309277027845383,\n",
       " -0.03518706187605858,\n",
       " 0.017601503059267998,\n",
       " 0.03776673972606659,\n",
       " 0.024583736434578896,\n",
       " 0.035969726741313934,\n",
       " -0.018826857209205627,\n",
       " 0.044718313962221146,\n",
       " -0.045678626745939255,\n",
       " 0.034775298088788986,\n",
       " -0.01982470043003559,\n",
       " -0.04870112985372543,\n",
       " 0.032311610877513885,\n",
       " -0.011565012857317924,\n",
       " 0.021644998341798782,\n",
       " 0.015746233984827995,\n",
       " -0.04829183965921402,\n",
       " -0.014721618965268135,\n",
       " -0.002236217027530074,\n",
       " 0.014409353025257587,\n",
       " 0.030544603243470192,\n",
       " 0.061715949326753616,\n",
       " -0.018756143748760223,\n",
       " 0.04099138453602791,\n",
       " 0.006017507519572973,\n",
       " 0.029441386461257935,\n",
       " 0.0671597346663475,\n",
       " 0.0025576308835297823,\n",
       " 0.028602181002497673,\n",
       " -0.018605684861540794,\n",
       " 0.05013180524110794,\n",
       " -0.0542902871966362,\n",
       " -0.03664889186620712,\n",
       " 0.040750712156295776,\n",
       " -0.044509004801511765,\n",
       " -0.07576945424079895,\n",
       " 0.0016938719199970365,\n",
       " -0.04662192612886429,\n",
       " -0.02760942094027996,\n",
       " 0.0392257384955883,\n",
       " 0.010924643836915493,\n",
       " -0.0143031757324934,\n",
       " 0.048677846789360046,\n",
       " 0.01945548690855503,\n",
       " -0.0165046788752079,\n",
       " 0.05750593915581703,\n",
       " 0.017886588349938393,\n",
       " 0.016367116943001747,\n",
       " 0.006838107947260141,\n",
       " -0.0027852400671690702,\n",
       " -0.028113022446632385,\n",
       " 0.03293533995747566,\n",
       " -0.008162261918187141,\n",
       " 0.016503559425473213,\n",
       " -0.0008890617173165083,\n",
       " -0.011331772431731224,\n",
       " 0.01560590323060751,\n",
       " -0.002747876103967428,\n",
       " -0.023822380229830742,\n",
       " 0.008317090570926666,\n",
       " -0.033890966325998306,\n",
       " 0.011247474700212479,\n",
       " -0.02326224185526371,\n",
       " -0.014204729348421097,\n",
       " -0.031394872814416885,\n",
       " 0.006071117240935564,\n",
       " -0.03975209593772888,\n",
       " 0.006350292824208736,\n",
       " 0.03685023635625839,\n",
       " 0.011773370206356049,\n",
       " -0.043271128088235855,\n",
       " 0.022107595577836037,\n",
       " -0.03222227841615677,\n",
       " 0.004633280448615551,\n",
       " 0.01861286163330078,\n",
       " -0.0461781807243824,\n",
       " -0.013411097228527069,\n",
       " -0.014593689702451229,\n",
       " -0.017189396545290947,\n",
       " -0.037615299224853516,\n",
       " -0.01175762340426445,\n",
       " 0.029062220826745033,\n",
       " -0.017437946051359177,\n",
       " 0.0454525351524353,\n",
       " -0.05209745094180107,\n",
       " -0.029428549110889435,\n",
       " 0.03321756049990654,\n",
       " 0.02435440942645073,\n",
       " -0.0358048640191555,\n",
       " 0.022126683965325356,\n",
       " -0.00966416671872139,\n",
       " 0.08779031038284302,\n",
       " -0.03464784100651741,\n",
       " -0.043734170496463776,\n",
       " 0.05736429989337921,\n",
       " -0.014013061299920082,\n",
       " 0.006000404711812735,\n",
       " -0.02421995811164379,\n",
       " 0.016350895166397095,\n",
       " 0.044808026403188705,\n",
       " -0.025562455877661705,\n",
       " 0.07690118998289108,\n",
       " 0.010970678180456161,\n",
       " 0.04207293689250946,\n",
       " -0.022715603932738304,\n",
       " -0.04467586800456047,\n",
       " -0.003055560402572155,\n",
       " -0.023600663989782333,\n",
       " -0.013115497305989265,\n",
       " 0.04398322477936745,\n",
       " 0.023938285186886787,\n",
       " -0.011075073853135109,\n",
       " -0.03778417780995369,\n",
       " 0.00021477344853337854,\n",
       " -0.010648282244801521,\n",
       " -0.05003296211361885,\n",
       " 0.07658620178699493,\n",
       " 0.03315397724509239,\n",
       " -0.02210102789103985,\n",
       " 0.05767066404223442,\n",
       " 0.0006767681916244328,\n",
       " -0.003242972306907177,\n",
       " 0.020267846062779427,\n",
       " 0.0006321387481875718,\n",
       " 0.0009972446132451296,\n",
       " -0.02512633241713047,\n",
       " -0.03888467326760292,\n",
       " 0.04662318155169487,\n",
       " 0.023061562329530716,\n",
       " -0.04041805863380432,\n",
       " -0.038651108741760254,\n",
       " -0.027900371700525284,\n",
       " 0.024071509018540382,\n",
       " 0.05060867220163345,\n",
       " 0.05143703520298004,\n",
       " -0.002084001898765564,\n",
       " 0.0024474747478961945,\n",
       " 0.032136015594005585,\n",
       " 0.019393740221858025,\n",
       " -0.07943607866764069,\n",
       " 0.02427038736641407,\n",
       " -0.06520397216081619,\n",
       " 0.031165381893515587,\n",
       " -0.035928234457969666,\n",
       " 0.03409767523407936,\n",
       " 0.030861197039484978,\n",
       " 0.03538651764392853,\n",
       " 0.042785514146089554,\n",
       " -0.03435273468494415,\n",
       " -0.015017978847026825,\n",
       " -0.03510842099785805,\n",
       " 0.006179507356137037,\n",
       " -0.05111760273575783,\n",
       " 0.012249006889760494,\n",
       " 0.005350593011826277,\n",
       " 0.03790914639830589,\n",
       " -0.07914953678846359,\n",
       " 0.017817426472902298,\n",
       " 0.0395965501666069,\n",
       " 0.036239635199308395,\n",
       " 0.012556263245642185,\n",
       " -0.050666097551584244,\n",
       " 0.057882554829120636,\n",
       " 0.06475129723548889,\n",
       " -0.0725456178188324,\n",
       " 0.03519894927740097,\n",
       " 0.030570028349757195,\n",
       " -0.006167229264974594,\n",
       " -0.011796296574175358,\n",
       " -0.008290175348520279,\n",
       " -0.017933540046215057,\n",
       " -0.04209362342953682,\n",
       " -0.012064228765666485,\n",
       " 0.00880552176386118,\n",
       " -0.05999321490526199,\n",
       " -0.03464368358254433,\n",
       " -0.08186905086040497,\n",
       " 0.0355706512928009,\n",
       " -0.04216013848781586,\n",
       " -0.10391668230295181,\n",
       " 0.0038084639236330986,\n",
       " -0.030506454408168793,\n",
       " 0.0399044007062912,\n",
       " 0.03539436310529709,\n",
       " -0.01851348765194416,\n",
       " -0.030506830662488937,\n",
       " 0.01296560000628233,\n",
       " 0.02962312288582325,\n",
       " -0.05594923719763756,\n",
       " 0.026137271896004677,\n",
       " 0.027979889884591103,\n",
       " -0.032783620059490204,\n",
       " -0.05861344188451767,\n",
       " 0.029305243864655495,\n",
       " 0.025631634518504143,\n",
       " 0.046621762216091156,\n",
       " -0.01578911766409874,\n",
       " -0.05855393409729004,\n",
       " -0.033567510545253754,\n",
       " -0.022099914029240608,\n",
       " 0.07099347561597824,\n",
       " -0.015482406131923199,\n",
       " -0.02221505530178547,\n",
       " 0.020550455898046494,\n",
       " 0.03193112462759018,\n",
       " 0.009649628773331642,\n",
       " 0.08112385869026184,\n",
       " 0.024486811831593513,\n",
       " -0.020967384800314903,\n",
       " -0.001703555346466601,\n",
       " 0.003984694369137287,\n",
       " 0.01214590948075056,\n",
       " 0.02251713164150715,\n",
       " 0.011797886341810226,\n",
       " -0.014598767273128033,\n",
       " -0.027774184942245483,\n",
       " 0.035769712179899216,\n",
       " -0.04636594280600548,\n",
       " 0.006575292441993952,\n",
       " 0.01091056503355503,\n",
       " 0.06001884862780571,\n",
       " -0.03792550787329674,\n",
       " 0.025552064180374146,\n",
       " -0.052944615483284,\n",
       " -0.00331985205411911,\n",
       " 0.04723644629120827,\n",
       " 0.04916655644774437,\n",
       " -0.012118092738091946,\n",
       " -0.015976974740624428,\n",
       " -0.023780548945069313,\n",
       " -0.020015906542539597,\n",
       " -0.016765648499131203,\n",
       " 0.017619017511606216,\n",
       " 0.09507094323635101,\n",
       " 0.02456720732152462,\n",
       " -0.00030371572938747704,\n",
       " 0.07726727426052094,\n",
       " 0.009286770597100258,\n",
       " 0.04579121246933937,\n",
       " 0.0006386045133695006,\n",
       " -0.0203663669526577,\n",
       " 0.05929982289671898,\n",
       " -0.009882405400276184,\n",
       " 0.017564021050930023,\n",
       " -0.05515163019299507,\n",
       " 0.016189292073249817,\n",
       " 0.028766026720404625,\n",
       " -0.03514404594898224,\n",
       " -0.04935841262340546,\n",
       " -0.02447367087006569,\n",
       " -0.02685004286468029,\n",
       " -0.009837007150053978,\n",
       " 9.710079029900953e-05,\n",
       " 0.019255781546235085,\n",
       " 0.016495689749717712,\n",
       " 0.019392136484384537,\n",
       " 0.014026164077222347,\n",
       " 0.044185783714056015,\n",
       " -0.0408172607421875,\n",
       " 0.058831170201301575,\n",
       " 0.033452264964580536,\n",
       " -0.07100701332092285,\n",
       " -0.01207928266376257,\n",
       " 0.017947617918252945,\n",
       " 0.026635218411684036,\n",
       " -0.042489077895879745,\n",
       " -0.025743063539266586,\n",
       " 0.04628248140215874,\n",
       " 0.02357054501771927,\n",
       " 0.012330091558396816,\n",
       " -0.019114600494503975,\n",
       " 0.04284172132611275,\n",
       " 0.020867055281996727,\n",
       " -0.020985012874007225,\n",
       " 0.049807094037532806,\n",
       " -0.06530244648456573,\n",
       " 0.06784137338399887,\n",
       " 0.06132720038294792,\n",
       " -0.025619087740778923,\n",
       " -0.01975896954536438,\n",
       " -0.028557993471622467,\n",
       " -0.0033664510119706392,\n",
       " -0.022265056148171425,\n",
       " 0.0277670007199049,\n",
       " 0.0376681424677372,\n",
       " -0.01844070851802826,\n",
       " -0.0666554793715477,\n",
       " -0.03576522693037987,\n",
       " -0.006980367470532656,\n",
       " -0.009456862695515156,\n",
       " 0.007616228424012661,\n",
       " -0.002117250580340624,\n",
       " -0.000508638215251267,\n",
       " -0.058485377579927444,\n",
       " 0.02196097932755947,\n",
       " 0.011461308225989342,\n",
       " -0.019124537706375122,\n",
       " 0.017011091113090515,\n",
       " -0.03894034028053284,\n",
       " -0.024677084758877754,\n",
       " -0.009032917208969593,\n",
       " 0.019948668777942657,\n",
       " -0.020086267963051796,\n",
       " 0.0046862466260790825,\n",
       " 0.0658910721540451,\n",
       " -0.021722840145230293,\n",
       " -0.0028560664504766464,\n",
       " 0.011400393210351467,\n",
       " -0.014010073617100716,\n",
       " -0.05337538197636604,\n",
       " -0.07439275830984116,\n",
       " 0.0002861053217202425,\n",
       " 0.04116436839103699,\n",
       " 0.03818747028708458,\n",
       " -0.012812647968530655,\n",
       " 0.05230933055281639,\n",
       " 0.018940966576337814,\n",
       " -0.048808012157678604,\n",
       " -0.06779120117425919,\n",
       " -0.01911095529794693,\n",
       " -0.028975164517760277,\n",
       " 0.004133264068514109,\n",
       " 0.01923450082540512,\n",
       " -0.020669246092438698,\n",
       " -0.003695683553814888,\n",
       " 0.009470553137362003,\n",
       " -0.041596852242946625,\n",
       " 0.045980364084243774,\n",
       " 0.029285280033946037,\n",
       " -0.07706877589225769,\n",
       " 0.006656208075582981,\n",
       " -0.005012008361518383,\n",
       " -0.017416084185242653,\n",
       " 0.007063459139317274,\n",
       " -0.05976015701889992,\n",
       " 0.0185412485152483,\n",
       " -0.0273988489061594,\n",
       " 0.005803277250379324,\n",
       " -0.041785452514886856,\n",
       " -0.0908936932682991,\n",
       " -0.006833197548985481,\n",
       " -0.014357824809849262,\n",
       " 0.08537802845239639,\n",
       " -0.05669703334569931,\n",
       " 0.06276111304759979,\n",
       " 0.0009012018563225865,\n",
       " -0.007769424468278885,\n",
       " -0.02144297957420349,\n",
       " -0.11318439245223999,\n",
       " 0.07541830092668533,\n",
       " 0.023151574656367302,\n",
       " 0.005866213236004114,\n",
       " -0.004821085371077061,\n",
       " -0.010738340206444263,\n",
       " 0.02703235298395157,\n",
       " 0.025599531829357147,\n",
       " 0.007024332880973816,\n",
       " -0.032584112137556076,\n",
       " -0.04185543581843376,\n",
       " -0.024687552824616432,\n",
       " -0.02051878534257412,\n",
       " -0.04894666746258736,\n",
       " 0.03619479760527611,\n",
       " -0.04281015321612358,\n",
       " 0.014844655990600586,\n",
       " 0.010251615196466446,\n",
       " 0.023320626467466354,\n",
       " 0.01871577650308609,\n",
       " 0.03378577157855034,\n",
       " -0.025527965277433395,\n",
       " 0.044417854398489,\n",
       " -0.02600604109466076,\n",
       " -0.0119530213996768,\n",
       " -0.055049628019332886,\n",
       " 0.022267477586865425,\n",
       " -0.010707407258450985,\n",
       " -0.026371469721198082,\n",
       " -0.009768350049853325,\n",
       " -0.01535708550363779,\n",
       " -0.019579773768782616,\n",
       " -0.021421188488602638,\n",
       " 0.006235864479094744,\n",
       " 0.0314040407538414,\n",
       " 0.031010085716843605,\n",
       " 0.004555661231279373,\n",
       " -0.031087100505828857,\n",
       " -0.014605932869017124,\n",
       " -0.003368874778971076,\n",
       " -0.028359955176711082,\n",
       " 0.057969674468040466,\n",
       " -0.09270115196704865,\n",
       " -0.009005305357277393,\n",
       " 0.022297324612736702,\n",
       " -0.02122938074171543,\n",
       " -0.03563996031880379,\n",
       " 0.004106925334781408,\n",
       " 0.006597382482141256,\n",
       " 0.03264277055859566,\n",
       " 0.03904365748167038,\n",
       " 0.02032073214650154,\n",
       " 0.005939505994319916,\n",
       " 0.010560653172433376,\n",
       " -0.002243859926238656,\n",
       " 0.02130184881389141,\n",
       " -0.02763022854924202,\n",
       " 0.014897515065968037,\n",
       " -0.020667249336838722,\n",
       " -0.09472247958183289,\n",
       " -0.0004307603812776506,\n",
       " -0.02479407750070095,\n",
       " 0.028932971879839897,\n",
       " 0.025980545207858086,\n",
       " 0.057643499225378036,\n",
       " -0.0374685563147068,\n",
       " 0.0006257054628804326,\n",
       " -0.01778700202703476,\n",
       " 0.017848286777734756,\n",
       " -0.00700916163623333,\n",
       " -0.026394061744213104,\n",
       " 0.03204090893268585,\n",
       " -0.005773015785962343,\n",
       " -0.012837935239076614,\n",
       " 0.016041608527302742,\n",
       " 0.030365966260433197,\n",
       " -0.025132445618510246,\n",
       " 0.0380871519446373,\n",
       " 0.026565272361040115,\n",
       " 0.061460208147764206,\n",
       " 0.018262824043631554,\n",
       " -0.025590986013412476,\n",
       " -0.014801396057009697,\n",
       " -0.009373162873089314,\n",
       " -0.05065552145242691,\n",
       " -0.01938270404934883,\n",
       " 0.04338742420077324,\n",
       " -0.008704069070518017,\n",
       " 0.020551657304167747,\n",
       " 0.010078946128487587,\n",
       " -0.022332625463604927,\n",
       " 0.013624574989080429,\n",
       " -0.029078511521220207,\n",
       " -0.02031247317790985,\n",
       " 0.04527844116091728,\n",
       " 0.008548842743039131,\n",
       " -0.044655926525592804,\n",
       " -0.04993825778365135,\n",
       " -0.0005616651615127921,\n",
       " -0.0019093779847025871,\n",
       " 0.029475873336195946,\n",
       " 0.08492345362901688,\n",
       " 0.02737259492278099,\n",
       " -0.019202347844839096,\n",
       " -0.011180019937455654,\n",
       " 0.0613800473511219,\n",
       " 0.0009942551841959357,\n",
       " -0.005685679614543915,\n",
       " 0.010302840732038021,\n",
       " 0.0048909238539636135,\n",
       " 0.03689644858241081,\n",
       " 6.452776142396033e-05,\n",
       " -0.02497044950723648,\n",
       " 0.006457015406340361,\n",
       " -0.03664189949631691,\n",
       " -0.03386320546269417,\n",
       " -0.009320611134171486,\n",
       " 0.027527937665581703,\n",
       " -0.006957217585295439,\n",
       " -0.0016937933396548033,\n",
       " 0.02136092633008957,\n",
       " 0.008775141090154648,\n",
       " 0.031389400362968445,\n",
       " 0.05911479890346527,\n",
       " 0.10196645557880402,\n",
       " 0.03833167254924774,\n",
       " 0.059265561401844025,\n",
       " -0.034477267414331436,\n",
       " 0.01983230747282505,\n",
       " -0.028979182243347168,\n",
       " -0.0006717467331327498,\n",
       " 0.023720132187008858,\n",
       " 0.009949897415935993,\n",
       " -0.027036644518375397,\n",
       " -0.02788533642888069,\n",
       " -0.009638091549277306,\n",
       " -0.017497442662715912,\n",
       " 0.05965723469853401,\n",
       " -0.023421915248036385,\n",
       " -7.17904549674131e-05,\n",
       " -0.023910334333777428,\n",
       " 0.010167197324335575,\n",
       " 0.06294538080692291,\n",
       " -0.007855839096009731,\n",
       " 0.009582506492733955,\n",
       " -0.00771779241040349,\n",
       " 0.010753695853054523,\n",
       " 0.029988912865519524,\n",
       " -0.0410747155547142,\n",
       " 0.014009366743266582,\n",
       " -0.016409873962402344,\n",
       " -0.025754181668162346,\n",
       " -0.029275324195623398,\n",
       " 0.06891670823097229,\n",
       " 0.00874270685017109,\n",
       " 0.023196490481495857,\n",
       " -0.038228556513786316,\n",
       " 0.016259821131825447,\n",
       " -0.013566256500780582,\n",
       " 0.025782182812690735,\n",
       " -0.020683975890278816,\n",
       " 0.04356987029314041,\n",
       " 0.03843095898628235,\n",
       " 0.011759771965444088,\n",
       " 0.0006424587918445468,\n",
       " 0.06934863328933716,\n",
       " 0.004451766610145569,\n",
       " 0.05257083848118782,\n",
       " 0.05299004167318344,\n",
       " -0.027428876608610153,\n",
       " 0.007362625561654568,\n",
       " -0.027196450158953667,\n",
       " -0.03716901317238808,\n",
       " -0.05996355041861534,\n",
       " -0.018047159537672997,\n",
       " 0.010596984066069126,\n",
       " -0.019895626232028008,\n",
       " -0.02837696112692356,\n",
       " -0.02666792832314968,\n",
       " 0.005059539806097746,\n",
       " -0.00711184972897172,\n",
       " 0.028563370928168297,\n",
       " 0.10317031294107437,\n",
       " 0.04524599015712738,\n",
       " -0.09671919792890549,\n",
       " -0.05298631638288498,\n",
       " -0.02709105610847473,\n",
       " -0.03117411397397518,\n",
       " -0.010037784464657307,\n",
       " 0.0028370970394462347,\n",
       " -0.01989951729774475,\n",
       " 0.054531022906303406,\n",
       " 0.017425885424017906,\n",
       " -0.031392212957143784,\n",
       " -0.0492844320833683,\n",
       " 0.012391205877065659,\n",
       " 0.021212412044405937,\n",
       " -0.010904794558882713,\n",
       " -0.02079067938029766,\n",
       " 0.010785725899040699,\n",
       " 0.0042291851714253426,\n",
       " 0.007526397705078125,\n",
       " 0.018077723681926727,\n",
       " -0.030186735093593597,\n",
       " -0.06504229456186295,\n",
       " -0.0060129123739898205,\n",
       " 0.04470229893922806,\n",
       " -0.0001683917362242937,\n",
       " 0.014180039055645466,\n",
       " 0.02072112262248993,\n",
       " 0.001374627579934895,\n",
       " 0.03986472263932228,\n",
       " 0.02338232658803463,\n",
       " 0.0028986725956201553,\n",
       " 0.018854621797800064,\n",
       " 0.018174119293689728,\n",
       " 0.008018970489501953,\n",
       " -0.001832504291087389,\n",
       " 0.004592920653522015,\n",
       " -0.01788954995572567,\n",
       " 0.004617960192263126,\n",
       " -0.028025709092617035,\n",
       " 0.04705401882529259,\n",
       " 0.027661263942718506,\n",
       " 0.0065150074660778046,\n",
       " -0.030028309673070908,\n",
       " -0.05390259250998497,\n",
       " -0.0013852387201040983,\n",
       " -0.01643216609954834,\n",
       " -0.06801334023475647,\n",
       " 0.05069683864712715,\n",
       " 0.06540688872337341,\n",
       " 0.01848502829670906,\n",
       " 0.03506237268447876,\n",
       " 0.015128708444535732,\n",
       " -0.0009853191440925002,\n",
       " 0.018667006865143776,\n",
       " -0.02371547929942608,\n",
       " -0.03277934715151787,\n",
       " -0.04126175865530968,\n",
       " 0.0004407509695738554,\n",
       " -0.006913974415510893,\n",
       " 0.001071878825314343,\n",
       " 0.04121888801455498,\n",
       " 0.033742137253284454,\n",
       " 0.06251147389411926,\n",
       " 0.07336639612913132,\n",
       " 0.036337900906801224,\n",
       " -0.020660797134041786,\n",
       " -0.023938000202178955,\n",
       " 0.02654903009533882,\n",
       " -0.009692799299955368,\n",
       " -0.04504105821251869,\n",
       " 0.022294068709015846,\n",
       " 0.03183344379067421,\n",
       " -0.013615928590297699,\n",
       " 0.09686916321516037,\n",
       " 0.05850844457745552,\n",
       " 0.05051637440919876,\n",
       " 0.06556273996829987,\n",
       " -0.030124453827738762,\n",
       " -0.05741645395755768,\n",
       " 0.08546410501003265,\n",
       " -0.09430325776338577,\n",
       " -0.0328102707862854,\n",
       " -0.026789216324687004,\n",
       " 0.03717803210020065,\n",
       " 0.08715295791625977,\n",
       " 0.0001604699791641906,\n",
       " -0.009505724534392357,\n",
       " -0.01792062073945999,\n",
       " 0.008379129692912102,\n",
       " 0.0796549916267395,\n",
       " 0.033412281423807144,\n",
       " 0.04523250833153725,\n",
       " 0.002415842143818736,\n",
       " -0.08875352889299393,\n",
       " -0.02112312614917755,\n",
       " 0.034831877797842026,\n",
       " 0.008336428552865982,\n",
       " 0.03964807465672493,\n",
       " 0.022455615922808647,\n",
       " 0.010564827360212803,\n",
       " -0.02183358184993267,\n",
       " -0.03671906143426895,\n",
       " 0.016374699771404266,\n",
       " -0.07664699852466583,\n",
       " -0.04381590336561203,\n",
       " 0.008805062621831894,\n",
       " -0.029425987973809242,\n",
       " 0.035350218415260315,\n",
       " 0.03271523490548134,\n",
       " -0.008388573303818703,\n",
       " -0.021349893882870674,\n",
       " 0.01584000512957573,\n",
       " -0.014425228349864483,\n",
       " -0.001280902768485248,\n",
       " -0.015345528721809387,\n",
       " -0.05014083534479141,\n",
       " 0.004639973398298025,\n",
       " 0.00799761712551117,\n",
       " 0.01279925275593996,\n",
       " 0.01869218423962593,\n",
       " 0.050975508987903595,\n",
       " -0.004513971973210573]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ae86b",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8dcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8feb528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68999868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32486a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0253c52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=os.path.join(os.getcwd(), \"data\", \"sample.pdf\")\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e544c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\pramod\\desktop\\krish_academy\\llmops_projects\\document_portal\\env\\lib\\site-packages (from pypdf) (4.14.1)\n",
      "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9d58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2ae1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "376cb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6670c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc6e89",
   "metadata": {},
   "source": [
    "### this is a experimental thing there is no deterministic way to split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5f06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "361efa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53ed226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f15a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 0, 'page_label': '1'}, page_content='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72cddd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce96aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96181a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "0,1,2,3\n",
    "page_lable=4\n",
    "actual page is 4 \n",
    "\n",
    "page_index=3\n",
    "page_lable=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "865ed5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 3,\n",
       " 'page_label': '4'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fd5afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 7,\n",
       " 'page_label': '8'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[200].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec192b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e25f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f92af725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ded599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6835d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=embedding_model.embed_documents(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c109387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents(docs[0].page_content)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed952e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "token->words\n",
    "\n",
    "chunk--> it is collection of words(token)[characters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e769025",
   "metadata": {},
   "source": [
    "1. in memory(faiss is in memory vector store,chroma)\n",
    "2. on disk storage(faiss you can persist over the disk,chroma)\n",
    "3. cloud storage(cloud variant of faiss is not available)(pinecone,weaviate,milvus,mongodbvectorsearch,astradb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd5d79",
   "metadata": {},
   "source": [
    "## This is a Retrieval proceesss\n",
    "\n",
    "means from the vectordatabase we are going to fetch or retrive or rank the most appropriate k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55503be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da52627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='abe9be4b-d3ae-4ce5-84b1-32bf33551253', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='84d12ca2-9cca-4a3c-a872-715dee1b3031', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='8b6e452b-23ae-4620-b10e-83fa6b9735bc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='2a321f4b-d981-481a-a9f0-3e4e786cba3c', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b59e667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d2f345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c52e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f6ff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a971b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b687780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='abe9be4b-d3ae-4ce5-84b1-32bf33551253', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='84d12ca2-9cca-4a3c-a872-715dee1b3031', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='8b6e452b-23ae-4620-b10e-83fa6b9735bc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='2a321f4b-d981-481a-a9f0-3e4e786cba3c', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='18ba578b-316d-47b8-b83f-ab23aee25b58', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='small delta (-0.9) between the \"clean\" subset performance and the sampling mean. No other dataset (for any\\nchoice ofL) appears to have benefitted from dataset contamination, and we omit results from these datasets\\nfor conciseness.\\n76'),\n",
       " Document(id='dab3e3a9-3753-49af-bf43-effc285c2444', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Human-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49'),\n",
       " Document(id='06940b04-b44a-4075-aed6-d76dc8861f2f', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='Contents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9'),\n",
       " Document(id='8fa2dece-04ca-4c08-91b9-e7cfb79e7d1e', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'),\n",
       " Document(id='1f92d997-9c8b-493b-9cda-de608b0a2d6e', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='Llama 2\\n7B 0.15 0.30 0.12 0.35 0.25 0.43 0.18 0.38 0.16 0.12 0.29 -0.1313B 0.14 0.35 0.23 0.29 0.23 0.57 0.20 0.52 0.22 0.12 0.29 -0.1734B 0.12 0.16 0.18 0.36 0.35 0.52 0.10 0.54 0.28 0.11 0.30 -0.1970B 0.16 0.21 0.17 0.35 0.30 0.60 0.18 0.67 0.26 0.12 0.30 -0.10\\nFine-tuned\\nChatGPT 0.15 0.22 0.05 0.24 0.31 0.35 0.09 0.42 0.19 0.09 0.23 0.06MPT-instruct 7B 0.13 0.29 0.12 0.34 0.35 0.53 0.28 0.56 0.27 0.02 0.32 -0.12Falcon-instruct 7B 0.11 0.21 0.21 0.28 0.34 0.23 0.31 0.45 0.23 0.22 0.29 -0.27'),\n",
       " Document(id='ed64d66b-9a69-488f-96dc-d87dcdd714b1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='be on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthis paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67ff01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a963e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='abe9be4b-d3ae-4ce5-84b1-32bf33551253', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2c9f69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8481a",
   "metadata": {},
   "source": [
    "### you can explore about keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2df7b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d5f07ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='abe9be4b-d3ae-4ce5-84b1-32bf33551253', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='84d12ca2-9cca-4a3c-a872-715dee1b3031', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='8b6e452b-23ae-4620-b10e-83fa6b9735bc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='2a321f4b-d981-481a-a9f0-3e4e786cba3c', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='18ba578b-316d-47b8-b83f-ab23aee25b58', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='small delta (-0.9) between the \"clean\" subset performance and the sampling mean. No other dataset (for any\\nchoice ofL) appears to have benefitted from dataset contamination, and we omit results from these datasets\\nfor conciseness.\\n76'),\n",
       " Document(id='dab3e3a9-3753-49af-bf43-effc285c2444', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Human-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49'),\n",
       " Document(id='06940b04-b44a-4075-aed6-d76dc8861f2f', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='Contents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9'),\n",
       " Document(id='8fa2dece-04ca-4c08-91b9-e7cfb79e7d1e', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'),\n",
       " Document(id='1f92d997-9c8b-493b-9cda-de608b0a2d6e', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='Llama 2\\n7B 0.15 0.30 0.12 0.35 0.25 0.43 0.18 0.38 0.16 0.12 0.29 -0.1313B 0.14 0.35 0.23 0.29 0.23 0.57 0.20 0.52 0.22 0.12 0.29 -0.1734B 0.12 0.16 0.18 0.36 0.35 0.52 0.10 0.54 0.28 0.11 0.30 -0.1970B 0.16 0.21 0.17 0.35 0.30 0.60 0.18 0.67 0.26 0.12 0.30 -0.10\\nFine-tuned\\nChatGPT 0.15 0.22 0.05 0.24 0.31 0.35 0.09 0.42 0.19 0.09 0.23 0.06MPT-instruct 7B 0.13 0.29 0.12 0.34 0.35 0.53 0.28 0.56 0.27 0.02 0.32 -0.12Falcon-instruct 7B 0.11 0.21 0.21 0.28 0.34 0.23 0.31 0.45 0.23 0.22 0.29 -0.27'),\n",
       " Document(id='ed64d66b-9a69-488f-96dc-d87dcdd714b1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\pramod\\\\Desktop\\\\KRISH_ACADEMY\\\\LLMOPS_Projects\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='be on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthis paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a2e3a",
   "metadata": {},
   "source": [
    "## Question: user question\n",
    "## Context: based on the question retrieving the info from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32650c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9189656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccc6ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82058939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dc8fe",
   "metadata": {},
   "source": [
    "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5b39444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f17d8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ef826e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbcf20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b10cb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c3976d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, I need to figure out how to answer the question about Llama 2's fine-tuning benchmark experiments based on the provided context. Let me start by going through the context to see what information is available.\\n\\nLooking through the context, I see several tables and some text. The tables mention different models, including Llama 2, with various sizes like 7B, 13B, 34B, and 70B. There are metrics like percentages and other numerical values. \\n\\nIn Table 3, there are entries for Llama 2 models with different sizes and some benchmark scores. The text mentions that these tables summarize overall performance on grouped academic benchmarks compared to open-source base models. It also talks about fine-tuned models, including ChatGPT, MPT-instruct, Falcon-instruct, and Llama 2-Chat. \\n\\nThere's a section on ablation experiments and hyperparameters, which might relate to fine-tuning. The hyperparameters include optimizer settings, learning rates, and other training details. Another table shows percentages for true, info, and combined metrics for various models, including fine-tuned versions like ChatGPT and Llama 2-Chat.\\n\\nI also notice that the context mentions improvements in Llama 2 over previous models, such as Llama 1, and other models like MPT and Falcon. The fine-tuned models seem to perform better, with higher percentages in some metrics.\\n\\nSo, putting this together, the fine-tuning experiments for Llama 2 likely involved comparing its performance against other models, both before and after fine-tuning. The tables provide specific benchmark scores, and the text explains the training parameters and improvements made. The results show that fine-tuned models like Llama 2-Chat and ChatGPT have higher performance metrics compared to their base counterparts.\\n\\nI should structure the answer by mentioning the comparison with other models, the benchmark results, the improvements from fine-tuning, and the specific models involved. I should also note the training details and how they contributed to the performance enhancements.\\n</think>\\n\\nThe fine-tuning benchmark experiments for Llama 2 involved comparing its performance with other models, both in their base and fine-tuned forms. The results, as shown in the context, indicate that fine-tuned models such as Llama 2-Chat and ChatGPT achieved higher performance metrics compared to their base counterparts. For instance, Llama 2-Chat models demonstrated improved scores across various benchmarks, with the 13B model achieving 62.18% in the true metric and 65.73% in the combined metric. \\n\\nThe experiments also highlighted the effectiveness of fine-tuning, with models like ChatGPT showing significant improvements, reaching 78.46% in the true metric and 79.92% in the combined metric. The context further details the training parameters, such as the use of the AdamW optimizer, cosine learning rate scheduling, and specific hyperparameters, which contributed to these performance enhancements. Overall, the fine-tuning process for Llama 2 was successful in boosting its performance across various academic benchmarks.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca813139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out the scaling trends for the reward model based on the provided context. Let me read through the context again to find relevant information.\\n\\nThe context starts by mentioning details on volume per batch in Table 26 and Figure 6. It says that Figure 6 reports these trends, showing that larger models get higher performance for a similar volume of data. That's a key point. It also notes that the scaling performance hasn't plateaued yet, meaning there's room for improvement with more data annotations.\\n\\nSo, the scaling trend seems positive—bigger models perform better, and adding more data helps. The fact that it hasn't plateaued suggests that increasing the model size or the dataset size will continue to enhance performance.\\n\\nI don't see any other specific details about scaling trends beyond what's mentioned here. The rest of the context talks about other aspects like margin-based loss, training objectives, and penalty terms, but those don't directly relate to scaling trends.\\n</think>\\n\\nThe scaling trends for the reward model indicate that larger models achieve higher performance with a similar amount of data. Additionally, the scaling performance has not yet plateaued, suggesting potential for further improvement with increased data annotations.\\n\\nAnswer: The scaling trends show that larger models obtain higher performance for a similar volume of data, and the scaling performance has not yet plateaued, indicating room for improvement with more data annotations.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"can you tell me Scaling trends for the reward model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826f5b4",
   "metadata": {},
   "source": [
    "# One Small task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26672a6a",
   "metadata": {},
   "source": [
    "### Take 10 pdfs keep it in same directory and create RAG on top of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1345b",
   "metadata": {},
   "source": [
    "In next class will discuss about the(will start with the modular coding)\n",
    "1. exception module\n",
    "2. logger module\n",
    "3. doc analyser\n",
    "4. doc compare\n",
    "5. utils and config\n",
    "   \n",
    "2 class\n",
    "\n",
    "2 more class api and other module\n",
    "\n",
    "2 more class for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1a8f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb65b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am sunny\\nmy name is sunny\\ni am sunny savita'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\".join([\"i am sunny\",\n",
    " \"my name is sunny\",\n",
    " \"i am sunny savita\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62407f6",
   "metadata": {},
   "source": [
    "### one specific sessin for all these topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. pydantic object and output parser\n",
    "2. history or memory\n",
    "3. cache\n",
    "4. token counter(cost analysis)\n",
    "5. pytest\n",
    "6. evaluation\n",
    "7. guadrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc144e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"available_keys\": [\"GOOGLE_API_KEY\", \"GROQ_API_KEY\"], \"timestamp\": \"2025-08-03T11:15:26.683802Z\", \"level\": \"info\", \"event\": \"Environment variables validated\"}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config\\\\config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelLoader\n\u001b[1;32m----> 2\u001b[0m loader\u001b[38;5;241m=\u001b[39m\u001b[43mModelLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\sunny\\document_portal\\utils\\model_loader.py:24\u001b[0m, in \u001b[0;36mModelLoader.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     22\u001b[0m load_dotenv()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_env()\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m=\u001b[39m\u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[1;32mc:\\users\\sunny\\document_portal\\utils\\config_loader.py:5\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_config\u001b[39m(config_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      6\u001b[0m         config\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config\\\\config.yaml'"
     ]
    }
   ],
   "source": [
    "from utils.model_loader import ModelLoader\n",
    "loader=ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b165f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8572e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647d06a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241m.\u001b[39mload_llm() \n",
      "\u001b[1;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "llm = loader.load_llm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69acae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 239\n",
      "\tPrompt Tokens: 12\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 227\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke\")\n",
    "    print(cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attach to your LLM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
